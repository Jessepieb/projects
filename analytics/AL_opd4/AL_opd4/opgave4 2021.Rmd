---
title: "Opgave 4"
author: "Jesse Piebenga"
output:
  word_document: default
  pdf_document: default
---

# Data
Data voor deze opgave: twts.csv (documentatie: twts.txt).

# Inleveren
Inleveren UITSLUITEND via Blackboard. Uiterste datum van inleveren: 21-3-2021
Inleveren UITSLUITEND in formaat .PDF, .DOC of .DOCX. 
Je kan, als je met RStudio werkt deze .Rmd file als basis gebruiken. Gebruik de "Knit" functie om pdf of docx te genereren.
Zet je naam in het document bij "author" hierboven..

# Inleiding
De opgave gaat over het analyseren van tweets. De vraag is om vast te stellen of een tweet een positieve dan wel een negatieve lading heeft.

Bij deze opgave begin je met ruwe data. In de data staan een aantal variabelen die je waarschijnlijk beter niet kan gebruiken. Het kan zijn dat een aantal tweets meerdere malen voorkomt. (Misschien is het beter om deze teksten eerst te ontdubbelen, misschien maakt dat ook niet zo veel uit). Het is aan jou om deze data zodanig te behandelen dat je de analyse goed kan uitvoeren. De afhankelijke variabele is "Sentiment".

De vraag is om een zo goed mogelijk CART-tree model te maken om uit de tekst van een tweet op te maken of het een positieve of negatieve lading heeft. De methode (text analytics) is uitgelegd op het college en is ook te vinden in de video's "Turning Tweets into Knowledge". 

Bij deze opgave wordt van je verwacht dat je zelf de juiste stappen zet om tot het gewenste eindresultaat te komen. Probeer zo goed mogelijk uit te leggen WAAROM je bepaalde stappen zet.

# Vraag 1
Maak een zo optimaal mogelijk CART-tree model om uit de tekst van een tweet het (positieve/negatieve) sentiment te halen. 

Let op: de Sentiment-variabele heeft DRIE verschillende waarden. Maak hiervan eerst een factor met slechts TWEE categorieen (positief/negatief). (Om te zorgen dat het een factor wordt kan je de functie as.factor gebruiken). 

Gebruik daarvoor de tekst-analyse methodiek uit de video's. Zorg er ook voor dat je de data splitst in een trainingsset en een testset, zodat je de validatie goed kan uitvoeren.

In je antwoorddocument verwacht ik in elk geval:

- Alle R-commando's 
- Relevant commentaar zodat het duidelijk is wat je doet en waarom je het doet
- Alle relevante R-uitvoer (bijvoorbeeld confusion matrices) 
- Alle relevante R-plots
- Niet alleen het opstellen van een model (op basis training data) maar ook validatie van het model (op basis van testdata). Validatie bestaat in elk geval uit confusion matrix + accuracy + sensitivity + specificity en een ROC-curve, plus een argumentatie over hoe goed het model de betreffende data kan voorspellen.
- Een goed onderbouwde conclusie 

```{r}
library(tm)
library(SnowballC)

library(caret)
library(e1071)

#read data from csv file
twts = read.csv("twts.csv", stringsAsFactors = FALSE)
#extract only the needed data
twts = subset(
  twts,
  select = c(Sentiment, Tweet)
)

#add new factor Negative (TRUE or FALSE)
twts$Negative = as.factor(twts$Sentiment < 2)

#-------------------------------------------------------------------------------
#Pre-processing

#load tweets into the Corpus format (collection of documents)
# making it easy to apply modifications to the provided text
corpus = Corpus(VectorSource(twts$Tweet))
#set all characters to lower
corpus = tm_map(corpus, tolower)
#remove all punctuation
corpus = tm_map(corpus, removePunctuation)
#remove all stop-words, these are not needed in our model
corpus = tm_map(corpus, removeWords, c(stopwords("english")))

#stem all words
corpus = tm_map(corpus, stemDocument)

#-------------------------------------------------------------------------------
#Bag of words

#get frequencies of all the words in our corpus
frequencies = DocumentTermMatrix(corpus)

#remove rare words
sparse = removeSparseTerms(frequencies, 0.995)

#make sparse into a data frame
tweetSparse = as.data.frame(as.matrix(sparse))
#correcting names , words that start with numbers will be changed
colnames(tweetSparse) = make.names(colnames(tweetSparse))

#add independent variable
tweetSparse$Negative = twts$Negative


#-------------------------------------------------------------------------------
#Splitting data

library(caTools)
#seed for pseudo random generator
set.seed(123)
#splitting the data
split = sample.split(tweetSparse$Negative, SplitRatio = 0.7)
#training set
trainsparse = subset(tweetSparse, split == TRUE)
#testing set
testsparse = subset(tweetSparse, split == FALSE)

#-------------------------------------------------------------------------------
#CART-Tree

library(rpart)
library(rpart.plot)

#create CART-Tree
tweetCART = rpart(Negative ~ ., data = trainsparse, method ="class")  
#plot Cart-Tree
prp(tweetCART)
#prediction from our model applied to our test-set
predictCart = predict(tweetCART, newdata = testsparse, type="class")

#Confusion Matrix
print(confusionMatrix(testsparse$Negative, predictCart))

#-------------------------------------------------------------------------------
#ROC-Curve

library(ROCR)
#create ROC predict
predictTreeROC = predict(tweetCART,newdata = testsparse)

ROCRpred = prediction(predictTreeROC[,2],testsparse$Negative)
perf = performance(ROCRpred, "tpr", "fpr")
#Plot the ROC_Curve
plot(perf,
     colorize = TRUE,
     print.cutoffs.at = seq(0, 1, 0.1))
#Addition of linear line
abline(0, 1)
#Calculate Area under the Curve
AUC = as.numeric(performance(ROCRpred, "auc")@y.values)
print(AUC)
#[1] 0.659984
```

# Vraag 2
Bij de eerste vraag heb je de 3 waarden voor Sentiment omgezet in 2 waarden voor de tekst-analyse. Je zou ook een CART-tree kunnen maken met daarbij alle drie waarden van Sentiment. Doe dit en geef het resultaat.

Gebruik cross-validation om de best mogelijke cp-parameter vast te stellen hiervoor. 

De confusion-matrix is nu 3 bij 3. Geef aan wat dat voor consequenties heeft voor je validatie. 

In je antwoorddocument verwacht ik in elk geval:

- Alle R-commando's 
- Relevant commentaar zodat het duidelijk is wat je doet en waarom je het doet
- Alle relevante R-uitvoer (bijvoorbeeld confusion matrices) 
- Alle relevante R-plots
- Je antwoord op de vraag in de laatste zin van vraag 2 (over de 3x3 matrix)
- Een goed onderbouwde conclusie 

```{r}
library(tm)
library(SnowballC)

library(caret)
library(e1071)

#read data from csv file
twts = read.csv("twts.csv", stringsAsFactors = FALSE)
#extract only the needed data
twts = subset(
  twts,
  select = c(Sentiment, Tweet)
)

twts$Sentiment = as.factor(twts$Sentiment)
#-------------------------------------------------------------------------------
#Pre-processing

#load tweets into the Corpus format (collection of documents)
# making it easy to apply modifications to the provided text
corpus = Corpus(VectorSource(twts$Tweet))
#set all characters to lower
corpus = tm_map(corpus, tolower)
#remove all punctuation
corpus = tm_map(corpus, removePunctuation)
#remove all stop-words, these are not needed in our model
corpus = tm_map(corpus, removeWords, c(stopwords("english")))

#stem all words
corpus = tm_map(corpus, stemDocument)

#-------------------------------------------------------------------------------
#Bag of words

#get frequencies of all the words in our corpus
frequencies = DocumentTermMatrix(corpus)

#remove rare words
sparse = removeSparseTerms(frequencies, 0.995)

#make sparse into a data frame
tweetSparse = as.data.frame(as.matrix(sparse))
#correcting names , words that start with numbers will be changed
colnames(tweetSparse) = make.names(colnames(tweetSparse))

#add independent variable
tweetSparse$Sentiment = twts$Sentiment


#-------------------------------------------------------------------------------
#Splitting data

library(caTools)
#seed for pseudo random generator
set.seed(123)
#splitting the data
split = sample.split(tweetSparse$Sentiment, SplitRatio = 0.7)
#training set
trainsparse = subset(tweetSparse, split == TRUE)
#testing set
testsparse = subset(tweetSparse, split == FALSE)

#-------------------------------------------------------------------------------
#CART-Tree

library(rpart)
library(rpart.plot)

#use k-fold cross validation
fitControl = trainControl(method = "cv", number = 10)
cartGrid = expand.grid(.cp=(1:50)*0.01)
cv = train(Sentiment~. , data = trainsparse, method="rpart",trControl = fitControl, tuneGrid = cartGrid)

print(cv)
#create CART-Tree
tweetCART = rpart(Sentiment ~ ., data = trainsparse, method ="class", control = rpart.control(cp=0.01))  
#plot Cart-Tree
prp(tweetCART)
#prediction from our model applied to our test-set
predictCart = predict(tweetCART, newdata = testsparse, type="class")
#Confusion Matrix
print(confusionMatrix(testsparse$Sentiment, predictCart))
```

# Eindbeoordeling Analytics

Als je alle vier opgaven hebt ingeleverd en deze zijn voldoende beoordeeld wordt je uitgenodigd om de resultaten van deze opgave in een assessment te bespreken met de docent. (Het assessment duurt ongeveer 8 minuten). Het eindcijfer van het vak Analytics wordt bepaald in het assessment. Zie voor meer informatie het document "Afsluitend assessment Analytics" op Blackboard.


